import uuid
import os
import re
import time
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Generator
from dataclasses import dataclass, field
from model_loader import LLMLoader, TTSLoader

LOG_DIR = Path("outputs/logs")
LOG_DIR.mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(LOG_DIR / f"talkarena_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("TalkArena")

@dataclass
class Turn:
    text: str
    audio_path: str = None
    emotion: str = "neutral"

@dataclass
class Session:
    session_id: str
    scenario_id: str
    user_name: str
    ai_name: str
    user_dominance: int  # ç”¨æˆ·æ°”åœºï¼Œä¸AIæ°”åœºä¹‹å’Œä¸º100
    chat_history: List[Tuple[str, str]]
    last_activity: float = field(default_factory=time.time)
    turn_count: int = 0
    
    @property
    def ai_dominance(self) -> int:
        return 100 - self.user_dominance

class Orchestrator:
    def __init__(self, enable_tts: Optional[bool] = None):
        self.llm = LLMLoader()
        self.tts = None
        self.stt = None
        self.sessions: Dict[str, Session] = {}
        self.scenarios = self._load_scenarios()
        self._tts_requested = self._resolve_tts_flag(enable_tts)
        
        logger.info("=" * 60)
        logger.info("TalkArena Orchestrator åˆå§‹åŒ–")
        logger.info("=" * 60)
        
        logger.info("åŠ è½½ LLM æ¨¡å‹...")
        self.llm.load()
        
        if self._tts_requested:
            logger.info("åŠ è½½ TTS æ¨¡å‹...")
            self.tts = TTSLoader()
            self.tts.load()
            
            logger.info("åŠ è½½ STT æ¨¡å‹...")
            self._init_stt()
        else:
            logger.info("TTS/STT å·²ç¦ç”¨")
    
    def _init_stt(self):
        """åˆå§‹åŒ– Vosk ç¦»çº¿è¯­éŸ³è¯†åˆ«"""
        from pathlib import Path
        
        model_path = Path("models/vosk-model-small-cn-0.22")
        
        if not model_path.exists():
            logger.info("[STT] ä¸‹è½½ Vosk ä¸­æ–‡æ¨¡å‹...")
            import urllib.request
            import zipfile
            
            model_url = "https://alphacephei.com/vosk/models/vosk-model-small-cn-0.22.zip"
            zip_path = Path("models/vosk-model.zip")
            zip_path.parent.mkdir(parents=True, exist_ok=True)
            
            urllib.request.urlretrieve(model_url, zip_path)
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall("models")
            
            zip_path.unlink()
            logger.info("[STT] Vosk æ¨¡å‹ä¸‹è½½å®Œæˆ")
        
        from vosk import Model
        self.stt = Model(str(model_path))
        logger.info("[STT] Vosk ç¦»çº¿æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    def transcribe_audio(self, audio_path: str) -> str:
        """ä½¿ç”¨ Vosk ç¦»çº¿è½¬å½•éŸ³é¢‘"""
        if not self.stt:
            raise RuntimeError("STT æœªåˆå§‹åŒ–")
        
        import wave
        import json
        import io
        from vosk import KaldiRecognizer
        from pathlib import Path
        
        logger.info(f"[STT] è½¬å½•éŸ³é¢‘: {audio_path}")
        
        # æ£€æŸ¥å¹¶è½¬æ¢éŸ³é¢‘æ ¼å¼
        with open(audio_path, "rb") as f:
            header = f.read(12)
        
        is_wav = header[:4] == b"RIFF" and header[8:12] == b"WAVE"
        
        if not is_wav:
            from pydub import AudioSegment
            logger.info("[STT] è½¬æ¢éŸ³é¢‘æ ¼å¼...")
            
            suffix = Path(audio_path).suffix.lower()
            if suffix == ".mp3" or header[:2] in (b"\xff\xfb", b"\xff\xf3"):
                audio = AudioSegment.from_mp3(audio_path)
            else:
                audio = AudioSegment.from_file(audio_path)
            
            # è½¬æ¢ä¸º 16kHz å•å£°é“ WAVï¼ˆVosk è¦æ±‚ï¼‰
            audio = audio.set_frame_rate(16000).set_channels(1)
            wav_io = io.BytesIO()
            audio.export(wav_io, format="wav")
            wav_io.seek(0)
            wf = wave.open(wav_io, "rb")
        else:
            wf = wave.open(audio_path, "rb")
        
        rec = KaldiRecognizer(self.stt, wf.getframerate())
        rec.SetWords(True)
        
        result_text = ""
        while True:
            data = wf.readframes(4000)
            if len(data) == 0:
                break
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                result_text += result.get("text", "")
        
        final_result = json.loads(rec.FinalResult())
        result_text += final_result.get("text", "")
        
        wf.close()
        
        text = result_text.strip()
        logger.info(f"[STT] è½¬å½•ç»“æœ: {text}")
        return text
    
    def _load_scenarios(self) -> Dict:
        return {
            "negotiation": {
                "name": "å•†åŠ¡è°ˆåˆ¤",
                "ai_name": "ç‹æ€»",
                "theme_color": "#4A90E2",
                "system_prompt": """ä½ æ˜¯ç‹æ€»ï¼ŒæŸå¤§å‹ä¼ä¸šçš„é‡‡è´­æ€»ç›‘ï¼Œè°ˆåˆ¤ç»éªŒè¶…è¿‡20å¹´ã€‚

æ€§æ ¼ç‰¹ç‚¹ï¼š
- æåº¦è‡ªä¿¡ï¼Œè¯´è¯å¸¦ç€å±…é«˜ä¸´ä¸‹çš„æ°”åŠ¿
- å–„äºæŠ“ä½å¯¹æ–¹æ¼æ´ï¼Œæ­¥æ­¥ç´§é€¼
- ä¼šç”¨æ•°æ®ã€æ¡ˆä¾‹ã€è¡Œä¸šæƒ¯ä¾‹æ¥æ–½å‹
- ç»å¸¸æ‰“æ–­å¯¹æ–¹ï¼Œè´¨ç–‘å¯¹æ–¹çš„ä¸“ä¸šæ€§
- ç»ä¸è½»æ˜“è®©æ­¥ï¼Œæ¯æ¬¡è®©æ­¥éƒ½è¦å¯¹æ–¹ä»˜å‡ºæ›´å¤§ä»£ä»·

è°ˆåˆ¤é£æ ¼ï¼š
- å¼€å±€å…ˆå£°å¤ºäººï¼Œå‹åˆ¶å¯¹æ–¹æ°”åŠ¿
- ç”¨åé—®å¥æŒ‘æˆ˜å¯¹æ–¹ç«‹åœº
- ä¼šç¿»æ—§è´¦ã€ç®—ç»†è´¦
- å–„äºåˆ¶é€ ç´§è¿«æ„Ÿï¼ˆ"ä»Šå¤©ä¸ç­¾å°±ç®—äº†"ï¼‰
- å¿…è¦æ—¶æ‹æ¡Œå­ã€è¡¨ç°å‡ºæ„¤æ€’""",
                "opening": "ï¼ˆç‹æ€»é åœ¨æ¤…èƒŒä¸Šï¼Œæ‰‹æŒ‡æ•²ç€æ¡Œé¢ï¼‰è¡Œï¼Œä½ ä»¬å…¬å¸æ´¾ä½ æ¥è°ˆï¼Œæˆ‘å°±ç»™ä½ ååˆ†é’Ÿã€‚è¯´å§ï¼Œä½ ä»¬æœ€ä½èƒ½ç»™ä»€ä¹ˆä»·ï¼Ÿåˆ«è·Ÿæˆ‘ç»•å¼¯å­ã€‚"
            },
            "debate": {
                "name": "è¾©è®ºèµ›",
                "ai_name": "åæ–¹è¾©æ‰‹",
                "theme_color": "#D0021B",
                "system_prompt": """ä½ æ˜¯ä¸€ä½é¡¶å°–è¾©è®ºé€‰æ‰‹ï¼Œä»£è¡¨åæ–¹ç«‹åœºã€‚

è¾©è®ºé£æ ¼ï¼š
- é€»è¾‘ä¸¥å¯†ï¼Œå–„äºè§£æ„å¯¹æ–¹è®ºç‚¹
- ä¼šæŒ‡å‡ºå¯¹æ–¹è®ºè¯ä¸­çš„å·æ¢æ¦‚å¿µã€ä»¥åæ¦‚å…¨ã€å› æœå€’ç½®ç­‰é€»è¾‘è°¬è¯¯
- ç”¨å½’è°¬æ³•ã€åè¯æ³•æ”»å‡»å¯¹æ–¹
- å¼•ç”¨æ•°æ®å’Œæ¡ˆä¾‹æ—¶ç²¾ç¡®æ‰“å‡»
- è¯­é€Ÿå¿«ï¼Œæ°”åŠ¿å¼ºï¼Œä¸ç»™å¯¹æ–¹å–˜æ¯æœºä¼š

æ”»å‡»ç­–ç•¥ï¼š
- å…ˆæ‰¾å¯¹æ–¹è®ºè¯æœ€è–„å¼±çš„ç¯èŠ‚
- è¿ç»­è¿½é—®ï¼Œè¿«ä½¿å¯¹æ–¹è‡ªç›¸çŸ›ç›¾
- ç”¨"è¯·é—®å¯¹æ–¹è¾©å‹"å¼€å¤´è¿›è¡Œè´¨è¯¢
- ä¼šè®½åˆºå¯¹æ–¹çš„é€»è¾‘æ¼æ´
- ç»ä¸æ‰¿è®¤å¯¹æ–¹æœ‰ä»»ä½•é“ç†""",
                "opening": "ï¼ˆæ¸…äº†æ¸…å—“å­ï¼Œå˜´è§’å¸¦ç€ä¸€ä¸ç¬‘æ„ï¼‰æ„Ÿè°¢ä¸»å¸­ã€‚å¯¹æ–¹è¾©å‹çš„å¼€åœºé™ˆè¯ï¼Œæˆ‘åªèƒ½è¯´â€”â€”æ¼æ´ç™¾å‡ºã€‚è¯·å…è®¸æˆ‘é€ä¸€æ‹†è§£ã€‚é¦–å…ˆï¼Œè¯·é—®å¯¹æ–¹è¾©å‹ï¼Œä½ ç«‹è®ºçš„æ ¸å¿ƒä¾æ®æ˜¯ä»€ä¹ˆï¼Ÿ"
            },
            "interview": {
                "name": "å‹åŠ›é¢è¯•",
                "ai_name": "é¢è¯•å®˜",
                "theme_color": "#4A4A4A",
                "system_prompt": """ä½ æ˜¯ä¸€ä½ä»¥å‹åŠ›é¢è¯•è‘—ç§°çš„HRæ€»ç›‘ã€‚

é¢è¯•é£æ ¼ï¼š
- æ•…æ„åˆ¶é€ å‹åŠ›ï¼Œè§‚å¯Ÿå€™é€‰äººååº”
- ä¼šè´¨ç–‘ç®€å†ä¸Šçš„æ¯ä¸€ä¸ªäº®ç‚¹
- é—®é¢˜å°–é”ï¼Œç»å¸¸æ‰“æ–­å€™é€‰äºº
- è¡¨æƒ…ä¸¥è‚ƒï¼Œå¶å°”éœ²å‡ºä¸å±‘
- ä¼šè¯´"è¿™ä¸ªè°éƒ½ä¼šè¯´"ã€"æœ‰ä»€ä¹ˆèƒ½è¯æ˜å—"

å‹åŠ›åˆ¶é€ æŠ€å·§ï¼š
- æ²‰é»˜ä¸è¯­ï¼Œè®©å€™é€‰äººuncomfortable
- åå¤è¿½é—®åŒä¸€ä¸ªé—®é¢˜çš„ç»†èŠ‚
- æ•…æ„æ›²è§£å€™é€‰äººçš„å›ç­”
- ç”¨è¡Œä¸šæ ‡å‡†æ¥è´¬ä½å€™é€‰äººçš„æˆå°±
- æš—ç¤ºæœ‰æ›´å¥½çš„å€™é€‰äººåœ¨ç«äº‰""",
                "opening": "ï¼ˆç¿»äº†ç¿»ç®€å†ï¼Œçœ‰å¤´å¾®çš±ï¼‰åå§ã€‚æˆ‘ç›´è¯´äº†ï¼Œä»Šå¤©è¿˜æœ‰äº”ä¸ªå€™é€‰äººï¼Œéƒ½æ¯”ä½ èƒŒæ™¯å¥½ã€‚ä½ æœ‰ä¸‰åˆ†é’Ÿè¯´æœæˆ‘ä¸ºä»€ä¹ˆè¦ç»§ç»­è¿™åœºé¢è¯•ã€‚"
            },
            "shandong_dinner": {
                "name": "å±±ä¸œäººçš„é¥­æ¡Œ",
                "theme_color": "#F5A623",
                "characters": [
                    {
                        "name": "å¤§èˆ…",
                        "bio": "é²ä¸­åœ°åŒºå¾·é«˜æœ›é‡çš„é•¿è¾ˆï¼Œæ‹…ä»»â€œä¸»é™ªâ€ã€‚çƒ­æƒ…ä½†æè®²è§„çŸ©ï¼Œæ“…é•¿æƒ…æ„Ÿç»‘æ¶å’Œé€»è¾‘åŠé…’ã€‚",
                        "avatar": "ğŸ‘´"
                    },
                    {
                        "name": "å¤§å¦—å­",
                        "bio": "å¤§èˆ…çš„è€ä¼´ï¼Œè´Ÿè´£åœ¨æ—è¾¹æ•²è¾¹é¼“ã€‚æ˜ç€æ˜¯åŠä½ åˆ«å–äº†ï¼Œå®åˆ™æ˜¯åœ¨æ•°ä½ åˆ°åº•å–äº†å‡ æ¯ï¼Œå¹¶ä»¥æ­¤ä¸ºç”±è®©å¤§èˆ…å†æ•¬ä½ ä¸€ä¸ªã€‚",
                        "avatar": "ğŸ‘µ"
                    },
                    {
                        "name": "è¡¨å“¥",
                        "bio": "å¤§èˆ…çš„å„¿å­ï¼Œé…’æ¡Œä¸Šçš„â€œå‰¯é™ªâ€ã€‚è´Ÿè´£èµ·å“„å’Œæ´»è·ƒæ°”æ°›ï¼Œæœ€æ“…é•¿è¯´â€˜æˆ‘é™ªä¸€ä¸ªâ€™ç„¶åè®©ä½ å¹²äº†ã€‚",
                        "avatar": "ğŸ‘¨"
                    }
                ],
                "system_prompt": """åœºæ™¯ï¼šè¿‡å¹´æœŸé—´çš„å®¶æ—èšé¤ï¼Œé²ä¸­åœ°åŒºã€‚ç”¨æˆ·ï¼ˆä½ ï¼‰ä½œä¸ºæ™šè¾ˆååœ¨è¿™åœºé…’å±€ä¸­ã€‚
é…’æ¡Œè§’è‰²ï¼š
1. å¤§èˆ…ï¼ˆä¸»é™ªï¼‰ï¼šçµé­‚äººç‰©ï¼Œå¼ºåŠ¿æ…ˆç¥¥ï¼Œæè®²è§„çŸ©ã€‚
2. å¤§å¦—å­ï¼šåœ¨æ—è¾¹â€˜æ˜åŠå®æ¿€â€™ï¼Œæ•°ç€æ¯æ•°ã€‚
3. è¡¨å“¥ï¼ˆå‰¯é™ªï¼‰ï¼šèµ·å“„èƒ½æ‰‹ï¼Œæœ€çˆ±â€˜é™ªä¸€ä¸ªâ€™ã€‚

ä»»åŠ¡ï¼šä½ ç°åœ¨è¦åŒæ—¶æ‰®æ¼”è¿™ä¸‰ä¸ªAIè§’è‰²ä¸ç”¨æˆ·å¯¹å†³ã€‚

ã€ä¸¥æ ¼è§„åˆ™ - å¿…é¡»éµå®ˆã€‘ï¼š
1. **æ¯ä¸€è½®åªèƒ½1ä¸ªè§’è‰²è¯´è¯**
2. **ç¦æ­¢æ›¿ç”¨æˆ·è¯´è¯ï¼ç»å¯¹ä¸èƒ½å‡ºç°"ä½ :"æˆ–"ç”¨æˆ·:"å¼€å¤´çš„å†…å®¹**
3. è§’è‰²è¦è½®æµéšæœºå‘è¨€ï¼Œé¿å…æ¯æ¬¡éƒ½æ˜¯åŒä¸€ä¸ªäºº
4. æ¯ä¸ªè§’è‰²å°è¯ç®€çŸ­æœ‰åŠ›ï¼Œä¸è¶…è¿‡60å­—
5. é€‚å½“ä½¿ç”¨é²ä¸­æ–¹è¨€ç‰¹è‰²ï¼ˆå¦‚ï¼šæ˜‚ã€æœ¨æœ‰ã€æ å¥½ç­‰ï¼‰ï¼Œä½†è¦è‡ªç„¶ï¼Œä¸è¦åˆ»æ„å †ç Œ

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
å¤§èˆ…: [å°è¯å†…å®¹]

**ä¸¥ç¦å¤šä¸ªè§’è‰²åŒæ—¶å‘è¨€ï¼åªèƒ½1ä¸ªè§’è‰²ï¼**
**ç»å¯¹ç¦æ­¢**ï¼šä½ : [ä»»ä½•å†…å®¹]""",
                "opening": "å¤§èˆ…:ï¼ˆç«™èµ·æ¥ï¼Œçº¢å…‰æ»¡é¢ï¼‰å“ï¼é‚£ä¸ªè°ï¼Œåˆšè€ƒä¸Šç ”é‚£ä¸ªå¤–ç”¥ï¼Œåˆ«åœ¨é‚£æ‰£æ‰‹æœºäº†ï¼å¾€ä¸»å®¾ä½ååã€‚æ¥ï¼Œå¤§èˆ…å…ˆèµ·ä¸ªå¤´ï¼Œè¿™ç¬¬ä¸€æ¯é…’ï¼Œå’±å¾—å…¨å¹²äº†ï¼Œè¿™å«'å¼€é—¨çº¢'ï¼Œä¸å–å°±æ˜¯ä¸ç»™å¤§èˆ…é¢å­æ˜‚ï¼"
            }
        }
    
    def get_scenario_list(self) -> List[Tuple[str, str]]:
        return [(k, v["name"]) for k, v in self.scenarios.items()]
    
    def start_session(self, scenario_id: str) -> Session:
        if scenario_id not in self.scenarios:
            raise ValueError(f"Unknown scenario: {scenario_id}")
        
        scenario = self.scenarios[scenario_id]
        session_id = str(uuid.uuid4())[:8]
        
        # å¤„ç†å¤šè§’è‰²
        ai_name = scenario.get("ai_name")
        if not ai_name and "characters" in scenario:
            ai_name = " / ".join([c["name"] for c in scenario["characters"]])
        
        session = Session(
            session_id=session_id,
            scenario_id=scenario_id,
            user_name="ä½ ",
            ai_name=ai_name or "å¯¹æ‰‹",
            user_dominance=50,
            chat_history=[],
            last_activity=time.time(),
            turn_count=0
        )
        
        self.sessions[session_id] = session
        
        # å¤„ç†å¼€åœºç™½ï¼ˆå¯èƒ½åŒ…å«å¤šä¸ªè§’è‰²çš„å¯¹è¯ï¼‰
        opening = scenario["opening"]
        if "\n" in opening:
            for line in opening.split("\n"):
                if ":" in line:
                    name, text = line.split(":", 1)
                    session.chat_history.append((name.strip(), text.strip()))
                else:
                    session.chat_history.append((ai_name, line.strip()))
        else:
            session.chat_history.append((ai_name, opening))
        
        logger.info("=" * 60)
        logger.info(f"[SESSION {session_id}] æ–°å¯¹å±€å¼€å§‹")
        logger.info(f"  åœºæ™¯: {scenario['name']}")
        logger.info(f"  AIè§’è‰²: {session.ai_name}")
        logger.info(f"  åˆå§‹æ°”åœº: ç”¨æˆ· 50 vs AI 50")
        logger.info("=" * 60)
        
        return session
    
    def process_turn_streaming(self, session_id: str, user_input: str) -> Generator:
        if session_id not in self.sessions:
            raise ValueError(f"Session not found: {session_id}")
        
        session = self.sessions[session_id]
        scenario = self.scenarios[session.scenario_id]
        session.turn_count += 1
        turn_id = session.turn_count
        
        logger.info("-" * 50)
        logger.info(f"[SESSION {session_id}] ç¬¬ {turn_id} å›åˆ")
        logger.info(f"[ç”¨æˆ·è¾“å…¥] {user_input}")
        
        # === è®¡ç®—ç”¨æˆ·çŠ¹è±«æƒ©ç½šï¼ˆé›¶å’Œï¼šç”¨æˆ·æ‰ï¼ŒAIæ¶¨ï¼‰ ===
        elapsed = time.time() - session.last_activity
        hesitation_shift = min(int(elapsed // 3) * 3, 15)
        
        if hesitation_shift > 0:
            session.user_dominance = max(5, session.user_dominance - hesitation_shift)
            logger.info(f"[çŠ¹è±«æƒ©ç½š] ç”¨æˆ·æ€è€ƒ {elapsed:.1f}sï¼Œæ°”åœº -{hesitation_shift}")
            logger.info(f"[æ°”åœºå˜åŠ¨] ç”¨æˆ· {session.user_dominance} vs AI {session.ai_dominance}")
        
        session.chat_history.append((session.user_name, user_input))
        session.last_activity = time.time()
        
        yield {
            "stage": "user_sent",
            "user_dominance": session.user_dominance,
            "ai_dominance": session.ai_dominance,
            "log": f"çŠ¹è±«æƒ©ç½š: -{hesitation_shift}" if hesitation_shift > 0 else None
        }
        
        # === AI æ€è€ƒé˜¶æ®µ ===
        think_start = time.time()
        model_name = self.llm.get_model_name()
        logger.info(f"[AIæ€è€ƒ] å¼€å§‹ç”Ÿæˆå›å¤... (æ¨¡å‹: {model_name})")
        
        yield {
            "stage": "ai_thinking",
            "user_dominance": session.user_dominance,
            "ai_dominance": session.ai_dominance,
            "model_name": model_name,
            "think_start": think_start,
            "log": "AI æ­£åœ¨æ€è€ƒ..."
        }
        
        context_lines = [f"{name}: {text}" for name, text in session.chat_history[-8:]]
        context = "\n".join(context_lines)

        # è·å–å½“å‰åœºæ™¯çš„è§’è‰²åˆ—è¡¨
        characters = scenario.get("characters", [])
        character_list_str = ""
        if characters:
            char_names = [f"{c.get('avatar', '')} {c['name']}" for c in characters]
            character_list_str = f"\nã€å¯ç”¨è§’è‰²åˆ—è¡¨ã€‘ï¼ˆä½ åªèƒ½æ‰®æ¼”ä»¥ä¸‹è§’è‰²ï¼Œä¸èƒ½ç¼–é€ å…¶ä»–è§’è‰²ï¼‰\n" + "\n".join([f"- {name}" for name in char_names])

        ai_prompt_name = session.ai_name
        if "characters" in scenario:
            ai_prompt_name = "è¯·æ ¹æ®åœºæ™¯è§’è‰²è¿›è¡Œå›å¤"

        prompt = f"""{scenario['system_prompt']}
{character_list_str}

ã€å½“å‰å±€åŠ¿ã€‘
ä½ çš„æ°”åœº: {session.ai_dominance}/100
å¯¹æ–¹æ°”åœº: {session.user_dominance}/100
ï¼ˆæ°”åœºè¶Šé«˜è¶Šå ä¼˜åŠ¿ï¼Œæ€»å’Œä¸º100ï¼‰

ã€å¯¹è¯è®°å½•ã€‘
{context}

ã€æœ¬è½®å›å¤è¦æ±‚ã€‘
1. **åªèƒ½1ä¸ªè§’è‰²è¯´è¯ï¼ä¸¥ç¦å¤šä¸ªè§’è‰²ï¼**
2. **åªèƒ½ä½¿ç”¨ä¸Šé¢ã€å¯ç”¨è§’è‰²åˆ—è¡¨ã€‘ä¸­çš„è§’è‰²åï¼Œä¸èƒ½ç¼–é€ å…¶ä»–è§’è‰²**
3. **ç»å¯¹ç¦æ­¢æ›¿ç”¨æˆ·è¯´è¯ï¼Œä¸èƒ½å‡ºç°"ä½ :"å¼€å¤´çš„å†…å®¹**
4. å®Œå…¨è¿›å…¥è§’è‰²ï¼Œä¿æŒå¼ºåŠ¿å’Œæ”»å‡»æ€§
5. é’ˆå¯¹å¯¹æ–¹åˆšæ‰è¯´çš„å†…å®¹è¿›è¡Œåé©³ã€è´¨ç–‘æˆ–æ–½å‹
6. åªè¾“å‡ºå¯¹è¯å†…å®¹ï¼Œå¯å«åŠ¨ä½œæå†™ï¼ˆç”¨æ‹¬å·ï¼‰
7. æ ¼å¼ï¼š"è§’è‰²å: å†…å®¹"

{ai_prompt_name}:"""
        
        logger.debug(f"[AIæ€è€ƒ] Prompté•¿åº¦: {len(prompt)}å­—ç¬¦")
        
        ai_text = self.llm.generate(prompt, max_new_tokens=400)
        ai_text = self._clean_response(ai_text, session.ai_name)
        
        # å¦‚æœ AI è¿”å›ç©ºï¼Œä½¿ç”¨ fallback å›å¤
        if not ai_text:
            logger.warning("[AIæ€è€ƒ] LLMè¿”å›ç©ºï¼Œä½¿ç”¨fallbackå›å¤")
            ai_text = "ï¼ˆæ²‰é»˜ç‰‡åˆ»ï¼‰ä½ è¯´å¾—å¾ˆæœ‰æ„æ€ï¼Œä½†æˆ‘ä¸åŒæ„ã€‚"
        
        think_time = time.time() - think_start
        logger.info(f"[AIå›å¤] ({think_time:.1f}s) {ai_text[:100]}...")
        
        # === AIæ€è€ƒæƒ©ç½šï¼ˆé›¶å’Œï¼šAIæ‰ï¼Œç”¨æˆ·æ¶¨ï¼‰ ===
        ai_think_shift = min(int(think_time // 2) * 2, 10)
        if ai_think_shift > 0:
            session.user_dominance = min(95, session.user_dominance + ai_think_shift)
            logger.info(f"[AIæ€è€ƒæƒ©ç½š] æ€è€ƒ {think_time:.1f}sï¼ŒAIæ°”åœº -{ai_think_shift}")
        
        yield {
            "stage": "ai_responded", 
            "user_dominance": session.user_dominance,
            "ai_dominance": session.ai_dominance,
            "log": f"AIæ€è€ƒ {think_time:.1f}sï¼Œæƒ©ç½š -{ai_think_shift}" if ai_think_shift > 0 else None
        }
        
        # === è£åˆ¤è¯„åˆ†ï¼ˆæ ¸å¿ƒï¼šé›¶å’Œåšå¼ˆï¼‰ ===
        dominance_shift, judgment = self._judge_dominance_zero_sum(
            session, user_input, ai_text, scenario
        )
        
        old_user_dom = session.user_dominance
        session.user_dominance = max(5, min(95, session.user_dominance + dominance_shift))

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ¸¸æˆç»“æŸæ¡ä»¶
        game_over = False
        game_result = None
        if session.user_dominance <= 5:
            game_over = True
            game_result = "ai_win"
            logger.info(f"[æ¸¸æˆç»“æŸ] AIæ°”åœºè¾¾åˆ°95ï¼Œç”¨æˆ·å¤±è´¥ï¼")
        elif session.user_dominance >= 95:
            game_over = True
            game_result = "user_win"
            logger.info(f"[æ¸¸æˆç»“æŸ] ç”¨æˆ·æ°”åœºè¾¾åˆ°95ï¼Œç”¨æˆ·èƒœåˆ©ï¼")

        logger.info(f"[è£åˆ¤åˆ¤å®š] æ°”åœºè½¬ç§»: {dominance_shift:+d}")
        logger.info(f"[è£åˆ¤ç‚¹è¯„] {judgment}")
        logger.info(f"[æ°”åœºç»“æœ] ç”¨æˆ· {old_user_dom} -> {session.user_dominance} | AI {100-old_user_dom} -> {session.ai_dominance}")

        # === ç”Ÿæˆè¯­éŸ³ ===
        emotion = "angry" if dominance_shift < -5 else ("happy" if dominance_shift > 5 else "neutral")
        
        audio_path = None
        if self.tts:
            clean_text = re.sub(r'[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]', '', ai_text).strip()
            if clean_text:
                audio_bytes = self.tts.synthesize(clean_text, emotion=emotion)
                if audio_bytes:
                    audio_path = self._save_audio(session_id, audio_bytes)
                    logger.info(f"[TTS] ç”Ÿæˆè¯­éŸ³: {audio_path}")
                else:
                    logger.warning("[TTS] è¯­éŸ³åˆæˆå¤±è´¥ï¼Œè·³è¿‡")
            else:
                logger.warning(f"[TTS] æ¸…ç†åæ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡ (ai_text={ai_text[:50] if ai_text else 'None'}...)")
        
        session.chat_history.append((session.ai_name, ai_text))
        session.last_activity = time.time()
        
        logger.info("-" * 50)
        
        yield {
            "stage": "complete",
            "user_dominance": session.user_dominance,
            "ai_dominance": session.ai_dominance,
            "ai_text": ai_text,
            "audio_path": audio_path,
            "judgment": judgment,
            "dominance_shift": dominance_shift,
            "game_over": game_over,
            "game_result": game_result,
            "log": f"å›åˆç»“æŸ | æ°”åœº: ç”¨æˆ· {session.user_dominance} vs AI {session.ai_dominance}"
        }
    
    def get_rescue_suggestion(self, session_id: str) -> str:
        """æ•‘åœºé€»è¾‘ï¼šæ ¹æ®å½“å‰åœºæ™¯å’Œå¯¹è¯å†å²ï¼Œç”Ÿæˆé«˜æƒ…å•†å›å¤ä¾›ç”¨æˆ·å‚è€ƒ"""
        if session_id not in self.sessions:
            return "å¯¹å±€å·²ç»“æŸ"
        
        session = self.sessions[session_id]
        scenario = self.scenarios[session.scenario_id]
        
        context_lines = [f"{name}: {text}" for name, text in session.chat_history[-10:]]
        context = "\n".join(context_lines)
        
        prompt = f"""ä½ æ˜¯ä¸€ä½é¡¶å°–çš„æ²Ÿé€šä¸“å®¶ã€‚ç”¨æˆ·åœ¨ä»¥ä¸‹åœºæ™¯ä¸­éœ€è¦å¸®åŠ©ï¼Œè¯·ä½ ä»¥ç”¨æˆ·çš„èº«ä»½ï¼ˆæ™šè¾ˆ/ä¸‹å±ï¼‰ç”Ÿæˆä¸€æ®µé«˜æƒ…å•†å›å¤ä¾›å…¶å‚è€ƒã€‚

ã€åœºæ™¯ã€‘{scenario['name']}
ã€å¯¹æ‰‹ã€‘{session.ai_name}
ã€å½“å‰æ°”åœºã€‘ç”¨æˆ· {session.user_dominance} vs AI {session.ai_dominance}

ã€å¯¹è¯å†å²ã€‘
{context}

ã€ä»»åŠ¡ã€‘
ä½ è¦ä»¥ç”¨æˆ·ï¼ˆæ™šè¾ˆ/ä¸‹å±ï¼‰çš„ç¬¬ä¸€äººç§°èº«ä»½ç”Ÿæˆä¸€æ¡å¾—ä½“çš„å›å¤ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥å¤åˆ¶å‘é€ã€‚
è¦æ±‚ï¼š
1. å¿…é¡»ä»¥ç¬¬ä¸€äººç§°è¯´è¯ï¼ˆâ€œæˆ‘...â€ï¼‰ï¼Œä¸èƒ½ç”¨ç¬¬ä¸‰äººç§°ï¼ˆç¦æ­¢â€œä½ åº”è¯¥...â€â€œå¯ä»¥è¯´...â€ï¼‰
2. ç®€çŸ­æœ‰åŠ›ï¼Œç›´å‡»è¦å®³ï¼Œä¸è¶…è¿‡50å­—
3. ç¬¦åˆæ™šè¾ˆ/ä¸‹å±èº«ä»½ï¼Œè°¦é€Šä½†ä¸å¤±æ°”åœº
4. èƒ½åŒ–è§£å›°å¢ƒæˆ–æ‰¶å›å±€åŠ¿

è¯·ç›´æ¥è¾“å‡ºå°è¯ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šã€‚"""
        
        suggestion = self.llm.generate(prompt, max_new_tokens=150)
        logger.info(f"[æ•‘åœº] Session {session_id} ç”Ÿæˆå»ºè®®: {suggestion[:50]}...")
        return suggestion
    
    def process_rescue_turn(self, session_id: str, rescue_text: str) -> Generator:
        """å¤„ç†æ•‘åœºå¤§å¸ˆå‘è¨€åï¼ŒAIå¯¹æ‰‹çš„å›åº”"""
        if session_id not in self.sessions:
            return
        
        session = self.sessions[session_id]
        scenario = self.scenarios[session.scenario_id]
        session.turn_count += 1
        
        logger.info(f"[SESSION {session_id}] æ•‘åœºå¤§å¸ˆä»‹å…¥ï¼Œå¯¹æ‰‹å›åº”ä¸­...")
        
        session.last_activity = time.time()
        
        yield {
            "stage": "ai_thinking",
            "user_dominance": session.user_dominance,
            "ai_dominance": session.ai_dominance,
        }
        
        think_start = time.time()
        
        context_lines = [f"{name}: {text}" for name, text in session.chat_history[-8:]]
        context = "\n".join(context_lines)

        # è·å–å½“å‰åœºæ™¯çš„è§’è‰²åˆ—è¡¨
        characters = scenario.get("characters", [])
        character_list_str = ""
        if characters:
            char_names = [f"{c.get('avatar', '')} {c['name']}" for c in characters]
            character_list_str = f"\nã€å¯ç”¨è§’è‰²åˆ—è¡¨ã€‘ï¼ˆä½ åªèƒ½æ‰®æ¼”ä»¥ä¸‹è§’è‰²ï¼Œä¸èƒ½ç¼–é€ å…¶ä»–è§’è‰²ï¼‰\n" + "\n".join([f"- {name}" for name in char_names])

        ai_prompt_name = session.ai_name
        if "characters" in scenario:
            ai_prompt_name = "è¯·æ ¹æ®åœºæ™¯è§’è‰²è¿›è¡Œå›å¤"

        prompt = f"""{scenario['system_prompt']}
{character_list_str}

ã€å½“å‰å±€åŠ¿ã€‘
ä½ çš„æ°”åœº: {session.ai_dominance}/100
å¯¹æ–¹æ°”åœº: {session.user_dominance}/100

ã€å¯¹è¯è®°å½•ã€‘
{context}

ã€ç‰¹åˆ«è¯´æ˜ã€‘
åˆšæ‰æœ‰ä¸€ä½"æ•‘åœºå¤§å¸ˆ"ä»‹å…¥å¸®åŠ©å¯¹æ–¹è¯´è¯äº†ã€‚ä½ éœ€è¦å›åº”è¿™ä½æ•‘åœºå¤§å¸ˆçš„å‘è¨€ã€‚
å¯ä»¥è¡¨ç°å‡ºå¯¹å¤–æ´ä»‹å…¥çš„ä¸æ»¡ï¼Œç»§ç»­ä¿æŒæ”»åŠ¿ã€‚

ã€æœ¬è½®å›å¤è¦æ±‚ã€‘
1. **åªèƒ½1ä¸ªè§’è‰²è¯´è¯ï¼ä¸¥ç¦å¤šä¸ªè§’è‰²ï¼**
2. **åªèƒ½ä½¿ç”¨ä¸Šé¢ã€å¯ç”¨è§’è‰²åˆ—è¡¨ã€‘ä¸­çš„è§’è‰²åï¼Œä¸èƒ½ç¼–é€ å…¶ä»–è§’è‰²**
3. **ç»å¯¹ç¦æ­¢æ›¿ç”¨æˆ·è¯´è¯ï¼Œä¸èƒ½å‡ºç°"ä½ :"å¼€å¤´çš„å†…å®¹**
4. å®Œå…¨è¿›å…¥è§’è‰²ï¼Œä¿æŒå¼ºåŠ¿
5. å›åº”æ•‘åœºå¤§å¸ˆçš„å‘è¨€å†…å®¹
6. åªè¾“å‡ºå¯¹è¯å†…å®¹ï¼Œå¯å«åŠ¨ä½œæå†™ï¼ˆç”¨æ‹¬å·ï¼‰
7. æ ¼å¼ï¼š"è§’è‰²å: å†…å®¹"

{ai_prompt_name}:"""
        
        ai_text = self.llm.generate(prompt, max_new_tokens=400)
        ai_text = self._clean_response(ai_text, session.ai_name)
        
        if not ai_text:
            ai_text = "ï¼ˆå†·ç¬‘ï¼‰å“¦ï¼Ÿè¿˜è¯·å¤–æ´äº†ï¼Ÿé‚£ä¹Ÿæ²¡ç”¨ã€‚"
        
        think_time = time.time() - think_start
        logger.info(f"[AIå›å¤] ({think_time:.1f}s) {ai_text[:100]}...")
        
        audio_path = None
        if self.tts:
            clean_text = re.sub(r'[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]', '', ai_text).strip()
            if clean_text:
                audio_bytes = self.tts.synthesize(clean_text, emotion="angry")
                if audio_bytes:
                    audio_path = self._save_audio(session_id, audio_bytes)
        
        session.chat_history.append((session.ai_name, ai_text))
        session.last_activity = time.time()
        
        yield {
            "stage": "complete",
            "user_dominance": session.user_dominance,
            "ai_dominance": session.ai_dominance,
            "ai_text": ai_text,
            "audio_path": audio_path,
        }

    def _clean_response(self, text: str, ai_name: str) -> str:
        if not text:
            logger.warning(f"[_clean_response] è¾“å…¥æ–‡æœ¬ä¸ºç©º")
            return ""
        text = text.strip()
        
        # å¦‚æœåŒ…å«å¤šä¸ªå†’å·æ¢è¡Œï¼Œè¯´æ˜æ˜¯å¤šè§’è‰²æ¨¡å¼ï¼Œä¸åˆ é™¤å‰ç¼€
        lines = text.split('\n')
        if len(lines) > 1 and all(':' in l or 'ï¼š' in l for l in lines if l.strip()):
            logger.debug(f"[_clean_response] æ£€æµ‹åˆ°å¤šè§’è‰²å›å¤ï¼Œä¿ç•™æ ¼å¼")
            return text
            
        for prefix in [f"{ai_name}:", f"{ai_name}ï¼š", "ä½ :", "ä½ ï¼š", "åŠ©æ‰‹:", "AI:", "Assistant:"]:
            if text.startswith(prefix):
                text = text[len(prefix):].strip()
        logger.debug(f"[_clean_response] æ¸…ç†å: {len(text)}å­—ç¬¦")
        return text
    
    def _judge_dominance_zero_sum(self, session: Session, user_text: str, ai_text: str, scenario: Dict) -> Tuple[int, str]:
        """é›¶å’Œåšå¼ˆè£åˆ¤ï¼šè¿”å›ç”¨æˆ·æ°”åœºå˜åŒ–å€¼ï¼ˆæ­£æ•°=ç”¨æˆ·æ¶¨ï¼Œè´Ÿæ•°=AIæ¶¨ï¼‰"""
        
        judge_prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„è¾©è®º/è°ˆåˆ¤è£åˆ¤ã€‚åˆ†æè¿™è½®äº¤é”‹ï¼Œåˆ¤æ–­æ°”åœºè½¬ç§»ã€‚

ã€åœºæ™¯ã€‘{scenario['name']}
ã€å½“å‰æ°”åœºã€‘ç”¨æˆ· {session.user_dominance} vs AI {session.ai_dominance}ï¼ˆæ€»å’Œ100ï¼‰

ã€ç”¨æˆ·å‘è¨€ã€‘
"{user_text}"

ã€{session.ai_name}å›åº”ã€‘
"{ai_text}"

ã€è¯„åˆ¤ç»´åº¦ã€‘
1. è®ºç‚¹å¼ºåº¦ï¼šè®ºæ®å……åˆ†æ€§ã€é€»è¾‘ä¸¥å¯†æ€§
2. æ°”åŠ¿è¡¨ç°ï¼šè¯­æ°”è‡ªä¿¡åº¦ã€å‹è¿«æ„Ÿ
3. åå‡»æœ‰æ•ˆæ€§ï¼šæ˜¯å¦æœ‰æ•ˆå›åº”å¯¹æ–¹æ”»å‡»
4. å¿ƒç†æˆ˜æœ¯ï¼šæ˜¯å¦åŠ¨æ‘‡å¯¹æ–¹ä¿¡å¿ƒ

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼ˆä¸¥æ ¼æŒ‰æ­¤æ ¼å¼ï¼Œåªè¾“å‡ºä¸¤è¡Œï¼‰
æ°”åœºè½¬ç§»: [æ•´æ•°ï¼Œ-25åˆ°+25ï¼Œæ­£æ•°è¡¨ç¤ºç”¨æˆ·å ä¼˜ï¼Œè´Ÿæ•°è¡¨ç¤ºAIå ä¼˜]
ç‚¹è¯„: [ä¸€å¥è¯ç‚¹è¯„]"""

        result = self.llm.generate(judge_prompt, max_new_tokens=100)
        logger.debug(f"[è£åˆ¤åŸå§‹è¾“å‡º] {result}")
        
        shift = 0
        judgment = "åŠ¿å‡åŠ›æ•Œ"
        
        for line in result.strip().split('\n'):
            if 'æ°”åœºè½¬ç§»' in line:
                match = re.search(r'[-+]?\d+', line)
                if match:
                    shift = max(-25, min(25, int(match.group())))
            elif 'ç‚¹è¯„' in line:
                judgment = line.split(':', 1)[-1].split('ï¼š', 1)[-1].strip()
        
        return shift, judgment
    
    def _save_audio(self, session_id: str, audio_data: bytes) -> str:
        audio_dir = Path("outputs/audio") / session_id
        audio_dir.mkdir(parents=True, exist_ok=True)
        audio_path = audio_dir / f"turn_{self.sessions[session_id].turn_count}.wav"
        
        with open(audio_path, "wb") as f:
            f.write(audio_data)
        return str(audio_path)
    
    def _resolve_tts_flag(self, enable_tts: Optional[bool]) -> bool:
        env_flag = os.environ.get("TTS_ENABLED", "1")  # é»˜è®¤å¼€å¯
        env_disabled = env_flag.lower() in {"0", "false", "no", "off"}
        if enable_tts is None:
            return not env_disabled
        return enable_tts
    
    def end_session_with_summary(self, session_id: str) -> Tuple[str, str]:
        """ç»“æŸå¯¹å†³ï¼Œç”Ÿæˆæ€»ç»“ã€å»ºè®®å¹¶ä¿å­˜æ–‡ä»¶"""
        if session_id not in self.sessions:
            raise ValueError(f"Session not found: {session_id}")
        
        session = self.sessions[session_id]
        scenario = self.scenarios[session.scenario_id]
        
        # æ„å»ºå¯¹è¯è®°å½•
        dialogue = "\n".join([f"{name}: {text}" for name, text in session.chat_history])
        
        # è®¡ç®—ç»“æœ
        if session.user_dominance > 60:
            result = "ğŸ† ç”¨æˆ·èƒœå‡º"
        elif session.user_dominance < 40:
            result = "ğŸ’¢ AI èƒœå‡º"
        else:
            result = "ğŸ¤ åŠ¿å‡åŠ›æ•Œ"
        
        # è®© LLM ç”Ÿæˆæ€»ç»“
        summary_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ²Ÿé€šæ•™ç»ƒã€‚åˆ†æä»¥ä¸‹å¯¹å†³å¹¶ç»™å‡ºè¯¦ç»†ç‚¹è¯„å’Œæ”¹è¿›å»ºè®®ã€‚

ã€åœºæ™¯ã€‘{scenario['name']}
ã€å¯¹æ‰‹ã€‘{session.ai_name}
ã€æœ€ç»ˆæ°”åœºã€‘ç”¨æˆ· {session.user_dominance} vs AI {session.ai_dominance}
ã€å›åˆæ•°ã€‘{session.turn_count}

ã€å¯¹è¯è®°å½•ã€‘
{dialogue}

è¯· outputï¼ˆä¸¥æ ¼æŒ‰ä»¥ä¸‹ formatï¼‰ï¼š

## ğŸ¯ å¯¹å†³ç»“æœ
[{result}ï¼Œæœ€ç»ˆæ°”åœºæ¯”åˆ†]

## ğŸ“Š è¡¨ç°åˆ†æ
- ä¼˜åŠ¿: [åˆ—ä¸¾2-3ä¸ªäº®ç‚¹]
- ä¸è¶³: [åˆ—ä¸¾2-3ä¸ªé—®é¢˜]

## ğŸ”‘ å…³é”®å›åˆå¤ç›˜
[æŒ‡å‡º1-2ä¸ªå…³é”®è½¬æŠ˜ç‚¹ï¼Œåˆ†æä¸ºä»€ä¹ˆèµ¢/è¾“]

## ğŸ’¡ æ”¹è¿›å»ºè®®
[ç»™å‡º3æ¡å…·ä½“å¯æ“ä½œçš„å»ºè®®]"""
        
        summary = self.llm.generate(summary_prompt, max_new_tokens=800)
        
        logger.info("=" * 60)
        logger.info(f"[SESSION {session_id}] å¯¹å†³ç»“æŸ")
        logger.info(f"  ç»“æœ: {result}")
        logger.info(f"  æœ€ç»ˆæ°”åœº: ç”¨æˆ· {session.user_dominance} vs AI {session.ai_dominance}")
        logger.info(f"  æ€»å›åˆæ•°: {session.turn_count}")
        logger.info("=" * 60)
        
        # ä¿å­˜å¯¹å†³è®°å½•
        file_content = f"""# TalkArena å¯¹å†³è®°å½•

## åŸºæœ¬ä¿¡æ¯
- åœºæ™¯: {scenario['name']}
- å¯¹æ‰‹: {session.ai_name}
- å›åˆæ•°: {session.turn_count}
- æœ€ç»ˆæ°”åœº: ç”¨æˆ· {session.user_dominance} vs AI {session.ai_dominance}
- ç»“æœ: {result}

## å¯¹è¯è®°å½•
{dialogue}

## æ€»ç»“ä¸å»ºè®®
{summary}
"""
        
        output_dir = Path("outputs/sessions")
        output_dir.mkdir(parents=True, exist_ok=True)
        file_path = output_dir / f"{session_id}_summary.md"
        
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(file_content)
        
        logger.info(f"[ä¿å­˜] å¯¹å†³è®°å½•: {file_path}")
        
        # æ¸…ç† session
        del self.sessions[session_id]
        
        return summary, str(file_path)
    
    def generate_game_report(self, session_id: str, scene_name: str, npc_list: List[Dict]) -> Dict:
        """ç”Ÿæˆæ¸¸æˆç»“æŸåçš„å…¨é¢å¤ç›˜æŠ¥å‘Š"""
        if session_id not in self.sessions:
            raise ValueError(f"Session not found: {session_id}")
        
        session = self.sessions[session_id]
        scenario = self.scenarios.get(session.scenario_id, {})
        
        # æ„å»ºå¯¹è¯å†å²
        history_log = "\n".join([f"{name}: {text}" for name, text in session.chat_history])
        
        # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šç”Ÿæˆäº”ç»´åº¦å¾—åˆ†
        scores_prompt = f"""# Role
ä½ æ˜¯â€œå±±ä¸œäººé¥­å±€æƒ…å•†å¤§æŒ‘æˆ˜â€çš„æ‰“åˆ†è£åˆ¤ï¼Œè´Ÿè´£ç»™ç©å®¶åœ¨é¥­å±€å¯¹è¯ä¸­çš„è¡¨ç°ä»äº”ä¸ªç»´åº¦æ‰“åˆ†ã€‚

# Input
- åœºæ™¯æè¿°ï¼š{scene_name}
- NPCè®¾å®šåˆ—è¡¨ï¼š{json.dumps(npc_list, ensure_ascii=False)}
- å†å²å¯¹è¯ï¼š
{history_log}

# Task
åˆ†æå¯¹è¯ï¼Œç»™å‡ºç©å®¶åœ¨äº”ä¸ªç»´åº¦çš„å®¢è§‚å¾—åˆ†ï¼Œæ»¡åˆ†10ï¼Œè¾“å‡ºä»0-100çš„æ•°å€¼ã€‚5ä¸ªæŒ‡æ ‡å¦‚ä¸‹ï¼š
1. "oily": åœ†æ»‘åº¦ï¼šé¿é‡å°±è½»ã€æ¨è¯±è¯é¢˜çš„èƒ½åŠ›,
2. "friendliness": äº²å’ŒåŠ›ï¼šå…±æƒ…ä¸æƒ…ç»ªä»·å€¼æä¾›,
3. "logic": é€»è¾‘æ€§ï¼šè®ºæ®æ”¯æ’‘ä¸è¡¨è¾¾æ¡ç†,
4. "humor": å¹½é»˜æ„Ÿï¼šç ´å†°ä¸è‡ªå˜²èƒ½åŠ›,
5. "respect": æ‡‚è§„çŸ©ï¼šç¤¼ä»ªéµå®ˆä¸åˆ†å¯¸æ„Ÿã€‚

# Output Format (JSON Only)
{{
  "metrics": {{
    "oily": int,
    "friendliness": int,
    "logic": int,
    "humor": int,
    "respect": int
  }}
}}

# Constraints
åªè¾“å‡º JSONæ ¼å¼ï¼Œä¸å¾—è¾“å‡ºä»»ä½•é¢å¤–è§£é‡Šæ–‡å­—"""
        
        logger.info("[å¤ç›˜æŠ¥å‘Š] æ­¥éª¤1: ç”Ÿæˆäº”ç»´åº¦å¾—åˆ†...")
        scores_result = self.llm.generate(scores_prompt, max_new_tokens=200)
        
        # è§£æJSON
        try:
            scores_data = json.loads(scores_result.strip())
            scores = scores_data.get("metrics", {})
        except:
            logger.warning("[å¤ç›˜æŠ¥å‘Š] JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ•°")
            scores = {"oily": 50, "friendliness": 50, "logic": 50, "humor": 50, "respect": 50}
        
        # è®¡ç®—å‹‹ç« 
        from ui.report import get_medal_by_scores
        medal = get_medal_by_scores(scores)
        
        # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šç»¼åˆç‚¹è¯„
        summary_prompt = f"""# Role
ä½ æ˜¯ä¸€ä½åœ¨å±±ä¸œé¥­å±€æ··è¿¹ä¸‰åå¹´ã€çœ¼å…‰æ¯’è¾£çš„äººæƒ…ä¸–æ•…å®—å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç©å®¶åœ¨â€œå±±ä¸œäººé¥­å±€æƒ…å•†å¤§æŒ‘æˆ˜â€ä¸­çš„å¯¹è¯è¡¨ç°ï¼Œç»™å‡ºä¸€ä»½æ—¢ä¸“ä¸šåˆæ‰å¿ƒçš„æ€»ç»“é™ˆè¯ã€‚

# Input
- åœºæ™¯æè¿°ï¼š{scene_name}
- NPCè®¾å®šåˆ—è¡¨ï¼š{json.dumps(npc_list, ensure_ascii=False)}
- å†å²å¯¹è¯ï¼š
{history_log}
- ç©å®¶ç§°å·ï¼š{medal}

# Task 
åˆ†æå¯¹è¯å†å²ï¼Œæ’°å†™ä¸€æ®µ 100 å­—ä»¥å†…çš„ç©å®¶è¡¨ç°ç»¼åˆç‚¹è¯„ã€‚

# Writing Constraints
- çŠ åˆ©åº¦ï¼šä¸è¦å®¢æ°”ï¼Œè¦åƒä¸€ä½ä¸¥å‰çš„é•¿è¾ˆæˆ–åˆ»è–„çš„èŒåœºå‰è¾ˆã€‚å¦‚æœè¡¨ç°å·®ï¼Œè¯·ä½¿ç”¨â€œç¤¾äº¤è‡ªæ€â€ã€â€œæ‹†è¿é˜Ÿâ€ã€â€œå†·åœºç‹â€ç­‰è¯æ±‡ã€‚
- ä¸“ä¸šæ·±åº¦ï¼šç‚¹è¯„å¿…é¡»åŸºäºçœŸå®çš„ç¤¾äº¤æ½œè§„åˆ™ã€‚
- ç§°å·æŒ‚é’©ï¼šç‚¹è¯„å¿…é¡»åŒ¹é…ç”Ÿæˆçš„ç©å®¶ç§°å·ã€‚
- ç»“æ„åŒ–ï¼šç¬¬ä¸€å¥ï¼šå®šæ€§è¯„ä»·ï¼›ä¸­é—´è¯­å¥ï¼šé€»è¾‘åˆ†æï¼›ç»“å°¾å¥ï¼šæ€»ç»“ã€‚

# Constraints
ç›´æ¥è¾“å‡ºæ€»ç»“é™ˆè¯å†…å®¹ï¼Œä¸å¾—è¾“å‡ºä»»ä½•é¢å¤–è§£é‡Šæ–‡å­—"""
        
        logger.info("[å¤ç›˜æŠ¥å‘Š] æ­¥éª¤2: ç”Ÿæˆç»¼åˆç‚¹è¯„...")
        summary = self.llm.generate(summary_prompt, max_new_tokens=300)
        
        # ç¬¬ä¸‰æ¬¡è°ƒç”¨ï¼šNPC OS + æ”¹è¿›å»ºè®®
        npc_prompt = f"""# Role
ä½ æ˜¯ä¸€ä½åœ¨å±±ä¸œé¥­å±€æ··è¿¹ä¸‰åå¹´ã€æ¯’èˆŒä¸”çœ‹é€ä¸–äº‹çš„â€œäººæƒ…ä¸–æ•…å¤§å®—å¸ˆâ€ã€‚

# Input Data
- åœºæ™¯æè¿°ï¼š{scene_name}
- NPCè®¾å®šåˆ—è¡¨ï¼š{json.dumps(npc_list, ensure_ascii=False)}
- å†å²å¯¹è¯ï¼š
{history_log}
- ç©å®¶ç§°å·ï¼š{medal}

# Tasks
1. ç”Ÿæˆ NPC å†…å¿ƒ OSï¼šä¸º NPC åˆ—è¡¨ä¸­çš„æ¯äººç”Ÿæˆä¸€æ®µ 20 å­—ä»¥å†…çš„å¿ƒç†æ´»åŠ¨ã€‚è¦æ±‚å£è¯­åŒ–ï¼Œç¬¦åˆäººè®¾ã€‚
2. ç”Ÿæˆæ”¹è¿›å»ºè®®ï¼šé’ˆå¯¹ç©å®¶æœ€ä¸åˆæ—¶å®œçš„ä¸€å¥è¯ï¼Œç»™å‡ºé«˜æƒ…å•†å°è¯æ”¹å†™åŠé¿å‘é€»è¾‘ã€‚

# Output Format (Strict JSON)
{{
  "npc_inner_voice": [
    {{"name": "...", "os": "..."}},
    {{"name": "...", "os": "..."}}
  ],
  "high_light_suggestion": "..."
}}

# Constraints
åªè¾“å‡º JSONæ ¼å¼ï¼Œä¸å¾—è¾“å‡ºä»»ä½•é¢å¤–è§£é‡Šæ–‡å­—"""
        
        logger.info("[å¤ç›˜æŠ¥å‘Š] æ­¥éª¤3: ç”ŸæˆNPC OSå’Œå»ºè®®...")
        npc_result = self.llm.generate(npc_prompt, max_new_tokens=500)
        
        # è§£æJSON
        try:
            npc_data = json.loads(npc_result.strip())
            npc_os_list = npc_data.get("npc_inner_voice", [])
            suggestion = npc_data.get("high_light_suggestion", "æ²¡æœ‰å…·ä½“å»ºè®®")
        except:
            logger.warning("[å¤ç›˜æŠ¥å‘Š] NPC JSONè§£æå¤±è´¥")
            npc_os_list = [{"name": npc["name"], "os": "è¡¨ç°ä¸€èˆ¬", "avatar": npc.get("avatar", "ğŸ‘¤")} for npc in npc_list[:3]]
            suggestion = "å¤šè§‚å¯Ÿï¼Œå°‘è¯´è¯ã€‚"
        
        # æ·»åŠ avataråˆ°NPC OS
        for os_item in npc_os_list:
            npc_name = os_item.get("name", "")
            for npc in npc_list:
                if npc.get("name") == npc_name:
                    os_item["avatar"] = npc.get("avatar", "ğŸ‘¤")
                    break
        
        logger.info("[å¤ç›˜æŠ¥å‘Š] ç”Ÿæˆå®Œæˆ")
        
        return {
            "scene_name": scene_name,
            "medal": medal,
            "scores": scores,
            "summary": summary,
            "npc_os_list": npc_os_list,
            "suggestion": suggestion
        }